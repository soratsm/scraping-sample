# ChatGPTへの入力サンプル

あなたは他人に教えるのが得意な熟練プログラマです。
次の内容に基づく
プログラムの組み方を
教えてください。
プログラム初心者でも理解できるよう具体的なコードを示しながら、分かりやすく段階的に教えてください。

あなたは他人に教えるのが得意な熟練プログラマです。次の内容の#準備を行ってください。プログラム初心者でも理解できるよう具体的なコードを示しながら、分かりやすく段階的に教えてください。

# 目的

動的webサイトのスクレイピング

# 使用言語

Python

# Frameworkや手法

採用：BeautifulSoup
  理由：HTMLやXMLファイルからデータを抽出するためのライブラリで、学習コストが低く使いやすいためおすすめです。

不採用：Scrapy
  理由：Webスクレイピング用のフレームワークで、高速にスクレイピングが可能ですが、学習コストが高いため初心者には不向きかもしれません。

# 手法

ログイン処理：Selenium

# 条件

* 汎用的に使えるよう、下記に#取得項目をどう変えるべきかコメントを追記
* ログイン処理がある
* 対象ページのURL、ログインユーザーID、パスワードは".env"に保持されている
* 取得結果はresultフォルダに"取得結果YYYYMMDD.txt"形式にて出力
* コードは最終的に一つのexeファイルまとめ、windows環境でダブルクリックにて動くようにする

# 取得項目

目次を作るため、指定ページのすべてのH1,H2,H3タグの文字列を取得

# 仕様

* 前処理
* 対象ページの特定処理
* ログイン処理
* 項目取得処理
* 取得項目変数格納
* ファイル出力
* 後処理

# 準備

* ".env"ファイルの作成とサンプルの追記
* resultフォルダの作成
* "readme.md"ファイルの作成とフレームワーク等の必要パッケージ一覧やインストールコマンドを追記

# フォルダ構成

```
project/
├── .env
├── main.py
├── chromedriver.exe
├── requirements.txt
├── result/
│   └── 取得結果YYYYMMDD.txt
└── readme.md
```

- `.env`: 対象ページのURL、ログインユーザーID、パスワードなどの機密情報を保持するためのファイルです。
- `main.py`: メインのPythonスクリプトファイルです。スクレイピング処理を記述します。
- `chromedriver.exe`: Seleniumで使用するChromeDriverの実行ファイルです。
- `requirements.txt`: このプロジェクトで使用するパッケージやライブラリを記述したファイルです。
- `result/`: スクレイピング結果を保存するフォルダです。
- `readme.md`: プロジェクトの説明や必要なパッケージのインストール方法などを記述したファイルです。

`chromedriver.exe`について
1. Chromeのバージョンを確認します。
ブラウザのメニューから「ヘルプ」→「Google Chromeについて」を選択すると、Chromeのバージョンが表示されます。
2. 確認したバージョンに対応するChromeDriverをダウンロードします。
https://sites.google.com/chromium.org/driver/?pli=1
上記サイトから、自分の環境に合わせたChromeDriverをダウンロードします。
